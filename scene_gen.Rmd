---
title: "CHILDES Utterance/Scene Generator"
author: "Kevin & George"
date: "`Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load packages


```{r cars}
library(tidyverse)
library(childesr)
```

## Look at summary data


```{r get-data, echo=FALSE}
d_transcripts <- get_transcripts(collection = "Eng-NA")

d_transcripts %>% group_by(corpus_id, corpus_name) %>%
  summarise(n = n(),
            mean_age = mean(target_child_age, na.rm=T), # Garvey mean_age=NaN...are they all e.g. 12 mos?
            sd_age = sd(target_child_age, na.rm=T))
```
## Get utterances

```{r}
d_utts <- get_utterances(corpus = "NewEngland") 

d_clean <- d_utts %>% filter(stem!="",
                             speaker_role!="Target_Child") # inconsistent labels? do we want Investigator?
  
d_clean %>% ggplot(aes(x=num_tokens)) + 
  geom_histogram() +
  theme_minimal()
```

## Example format

```{r}
# for testing:
mat = matrix(c(1,2, 1,3), nrow=2, ncol=2, byrow=T) # knowledge representation (what a model might learn)

# list of training utterances / scenes
ord = list(words = list(c(1,2), # utterance 1 (word indices)
                        c(2,1,3)), # utterance 2
           objs = list(c(1,2,3), # scene 1 (referent indices)
                       c(1,2,7,8))) # scene 2

# ord = combined_data$`201`$train

# models iterate over utterances, and sample/associate/hypothesize words -> referents in the scene
```


## Convert utterances to indexed POS vectors

```{r}
# take rows of utterances (e.g. "is that a block"), want 
# 1) dictionary of all unique stem@PoS combinations (frequency table)
# dictionary tibble row example:
# index stem_pos stem  pos frequency/count
# 1     block@n  block n   45

# we actually want to do this across all corpora

# dictionary determines possible knowledge matrix
# matrix(0, nrow=nrow(dictionary), ncol=ncol(dictionary))
```


## First pass generator

```{r}
source("load_corpus_data.R")

# if easier, only need to do one corpus at a time

fetch_data <- function(corpus_names, min_age, max_age) {
  dat <- get_utterances(corpus = corpus_names)
  dat <- dat %>% filter(target_child_age <= max_age, 
                        target_child_age >= min_age,
                        stem!="",
                        speaker_role!="Target_Child")
  return(dat)
}


generator <- function(utterances, scene_size, include_POS = c("n")) { 
  # , desiredSpeakers=c("")
  # every scene_size utterances is a 'scene' (e.g., 5 utterances)
  # group_by child, and sample N 
  refs_scene = c()
  for (i in 1:nrow(utterances)) {
    pos = str_split(utterances[i, "part_of_speech"], " ")[[1]]
    words = str_split(utterances[i, "stem"], " ")[[1]]
    if (length(pos) != length(words)) {
      next
    }
    for (j in 1:length(pos)) {
      for (p in include_POS) {
        if (startsWith(pos[j], p)) {
          refs_scene = append(refs_scene, words[j])
        }
      }
    }
    if ((i %% scene_size) == 0) {
      for (j in (i - scene_size + 1):i) {
        utterances[j, "refs"] = paste(refs_scene, collapse = " ")
      }
      refs_scene = c()
    }
  }
  train_words = c(utterances["stem"])[[1]]
  train_refs = c(utterances["refs"])[[1]]
  utterances_ord = create_scenes(train_words, train_refs)
  return(utterances_ord)
}

# want to be able to specify array of PoS to include: nouns, adjectives, verbs
# noun: n, adjective: adj, verb: v, adv: adv, pronoun: pro, determiner: det
# prepopsition: prep
# note: v does not include modals (mod) and copulas (cop)
utts <- fetch_data(c("Brown", "NewEngland"), 10, 14)
gen_adj <- generator(utts, 5, c("adj"))
```

## Data questions

What is the average length of utterance per corpus? (maybe with sd)
What is average length of utterance by age? (plot)
What is average length of utternace with only nouns? .. with nouns, verbs, adjectives? (adverbs?)
